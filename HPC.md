# Thesis

# HPC 
### [`-> Browser dashboard <-`](https://login.hpc.ugent.be/)

## A Typical workflow
### [`1. Connect to the login nodes`](#1-connect-to-the-login-nodes-1)
### [`2. Transfer your files to the HPC`](#2-transfer-your-files-to-the-hpc-1)
### [`3. Optional: compile your code and test it`](#3-optional-compile-your-code-and-test-it-1)
### [`4. Create a job script and submit your job`](#4-create-a-job-script-and-submit-your-job-1)
### [`5. Wait for job to be executed`](#5-wait-for-job-to-be-executed-1)
### [`6. Study the results generated by your jobs`](#6-study-the-results-generated-by-your-jobs)


## 1. Connect to the login nodes

using ssh:

```
$ ssh vsc40000@login.hpc.ugent.be
```

_replace vsc40000 with your own VSC id_

I set up some handy commands / variables which are kept in a file named baserc, 
you can edit the variables in there and then install it using `source baserc`.



## 2. Transfer your files to the HPC

using scp:

```
# from local to hpc
$ scp /path/to/local/file vsc40000login.hpc.ugent.be:~ 

# from hpc to local
$ scp vsc40000login.hpc.ugent.be:~/path/to/local/file .
```

_replace vsc40000 with your own VSC id_

**TODO**
- [ ] try out `tar | ssh` method -> ask chatgpt "how does a "tar | ssh" method work to transfer files"
  - source tar-ssh method: http://www.spikelab.org/blog/transfer-largedata-scp-tarssh-tarnc-compared.html#:~:text=Scp%20is%20by%20far%20the,as%20good%20as%20over%20nc.



## 3. Optional: compile your code and test it 


## 4. Create a job script and submit your job
### Creating a job script
0. unload existing modules using `module purge`
1. load modules using `module load <module_name>`
    - tip: find modules using `module avail <keyword>`
    - tip: view loaded modules using `module list`
    - tip: unload modules using `module unload <module_name>`
2. swap to preferred cluster using `module swap cluster/<cluster_name>`
    - tip: find clusters using `module avail cluster`
        - the specs of each cluster can be found [here](https://www.ugent.be/hpc/en/infrastructure)

tips:
- don't compile on one cluster and run on another, it will not work
  - you can however compile on a cluster in one job and then run on that same cluster in another job
- you can send commands over to the hpc like so: `ssh <vscuser>@login.hpc.ugent.be "<command1>; <command2>"`
### Submitting a job
First, swap to the right cluster using `module swap cluster/<cluster-name>`

Then submit your job on that cluster using `qsub`:
```
$ qsub <job_script>
```
- tip: see help with `qsub -h`
- tip: see status of jobs on current cluster with `qstat`

## 5. Wait for job to be executed
You can also make jobs depend on other jobs, so that job2 only starts once job1 has finished (succesfully).
```
$ FIRST_ID=$(qsub job1.sh)
$ qsub -W depend=afterok:$FIRST_ID job2.sh
```

although this does not seem to work when running the jobs on different clusters, the job id's are cluster related.


## 6. Study the results generated by your jobs
_either on the cluster or after downloading them locally_

Each job produces 2 new files:
- `<job_name>.o<job_id>`: contains the output of the job
- `<job_name>.e<job_id>`: contains the errors (& warnings) of the job
